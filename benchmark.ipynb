{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "298fe91f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Everyday\\anaconda3\\envs\\scipy\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\Everyday\\anaconda3\\envs\\scipy\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\Everyday\\anaconda3\\envs\\scipy\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import elasticdeform\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7f8ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import numpy as np\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "x_train_full = x_train_full.reshape(x_train_full.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "\n",
    "x_train_full = x_train_full.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "x_train_augmented, x_val, y_train_augmented, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c2272a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.6257 - accuracy: 0.7982 - val_loss: 0.1714 - val_accuracy: 0.9498 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3577 - accuracy: 0.8887 - val_loss: 0.1242 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.3022 - accuracy: 0.9069 - val_loss: 0.1234 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.2698 - accuracy: 0.9164 - val_loss: 0.0876 - val_accuracy: 0.9742 - lr: 9.6000e-04\n",
      "Epoch 5/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.2482 - accuracy: 0.9220 - val_loss: 0.0901 - val_accuracy: 0.9724 - lr: 9.6000e-04\n",
      "Epoch 6/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.2352 - accuracy: 0.9277 - val_loss: 0.0791 - val_accuracy: 0.9772 - lr: 9.6000e-04\n",
      "Epoch 7/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.2222 - accuracy: 0.9314 - val_loss: 0.0724 - val_accuracy: 0.9787 - lr: 9.2160e-04\n",
      "Epoch 8/200\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.2163 - accuracy: 0.9328 - val_loss: 0.0730 - val_accuracy: 0.9777 - lr: 9.2160e-04\n",
      "Epoch 9/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.2028 - accuracy: 0.9372 - val_loss: 0.0768 - val_accuracy: 0.9770 - lr: 9.2160e-04\n",
      "Epoch 10/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.2028 - accuracy: 0.9376 - val_loss: 0.0689 - val_accuracy: 0.9799 - lr: 9.2160e-04\n",
      "Epoch 11/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1939 - accuracy: 0.9407 - val_loss: 0.0698 - val_accuracy: 0.9803 - lr: 8.8474e-04\n",
      "Epoch 12/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1879 - accuracy: 0.9420 - val_loss: 0.0652 - val_accuracy: 0.9803 - lr: 8.8474e-04\n",
      "Epoch 13/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1838 - accuracy: 0.9437 - val_loss: 0.0633 - val_accuracy: 0.9814 - lr: 8.8474e-04\n",
      "Epoch 14/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1787 - accuracy: 0.9458 - val_loss: 0.0587 - val_accuracy: 0.9830 - lr: 8.4935e-04\n",
      "Epoch 15/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1758 - accuracy: 0.9459 - val_loss: 0.0594 - val_accuracy: 0.9824 - lr: 8.4935e-04\n",
      "Epoch 16/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1705 - accuracy: 0.9477 - val_loss: 0.0547 - val_accuracy: 0.9837 - lr: 8.4935e-04\n",
      "Epoch 17/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1653 - accuracy: 0.9491 - val_loss: 0.0566 - val_accuracy: 0.9832 - lr: 8.1537e-04\n",
      "Epoch 18/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1620 - accuracy: 0.9492 - val_loss: 0.0534 - val_accuracy: 0.9843 - lr: 8.1537e-04\n",
      "Epoch 19/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1629 - accuracy: 0.9505 - val_loss: 0.0530 - val_accuracy: 0.9853 - lr: 8.1537e-04\n",
      "Epoch 20/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1580 - accuracy: 0.9514 - val_loss: 0.0521 - val_accuracy: 0.9861 - lr: 8.1537e-04\n",
      "Epoch 21/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1568 - accuracy: 0.9523 - val_loss: 0.0546 - val_accuracy: 0.9850 - lr: 7.8276e-04\n",
      "Epoch 22/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1493 - accuracy: 0.9549 - val_loss: 0.0543 - val_accuracy: 0.9847 - lr: 7.8276e-04\n",
      "Epoch 23/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1518 - accuracy: 0.9529 - val_loss: 0.0499 - val_accuracy: 0.9847 - lr: 7.8276e-04\n",
      "Epoch 24/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1510 - accuracy: 0.9544 - val_loss: 0.0509 - val_accuracy: 0.9851 - lr: 7.5145e-04\n",
      "Epoch 25/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1455 - accuracy: 0.9560 - val_loss: 0.0476 - val_accuracy: 0.9857 - lr: 7.5145e-04\n",
      "Epoch 26/200\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.1443 - accuracy: 0.9561 - val_loss: 0.0480 - val_accuracy: 0.9856 - lr: 7.5145e-04\n",
      "Epoch 27/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1476 - accuracy: 0.9559 - val_loss: 0.0436 - val_accuracy: 0.9868 - lr: 7.2139e-04\n",
      "Epoch 28/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1381 - accuracy: 0.9583 - val_loss: 0.0434 - val_accuracy: 0.9871 - lr: 7.2139e-04\n",
      "Epoch 29/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1418 - accuracy: 0.9575 - val_loss: 0.0471 - val_accuracy: 0.9860 - lr: 7.2139e-04\n",
      "Epoch 30/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1383 - accuracy: 0.9583 - val_loss: 0.0474 - val_accuracy: 0.9864 - lr: 7.2139e-04\n",
      "Epoch 31/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1374 - accuracy: 0.9583 - val_loss: 0.0444 - val_accuracy: 0.9872 - lr: 6.9253e-04\n",
      "Epoch 32/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1328 - accuracy: 0.9593 - val_loss: 0.0424 - val_accuracy: 0.9872 - lr: 6.9253e-04\n",
      "Epoch 33/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1351 - accuracy: 0.9577 - val_loss: 0.0452 - val_accuracy: 0.9869 - lr: 6.9253e-04\n",
      "Epoch 34/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1331 - accuracy: 0.9598 - val_loss: 0.0438 - val_accuracy: 0.9866 - lr: 6.6483e-04\n",
      "Epoch 35/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1322 - accuracy: 0.9604 - val_loss: 0.0409 - val_accuracy: 0.9877 - lr: 6.6483e-04\n",
      "Epoch 36/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1274 - accuracy: 0.9610 - val_loss: 0.0412 - val_accuracy: 0.9883 - lr: 6.6483e-04\n",
      "Epoch 37/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1274 - accuracy: 0.9612 - val_loss: 0.0452 - val_accuracy: 0.9871 - lr: 6.3824e-04\n",
      "Epoch 38/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1271 - accuracy: 0.9617 - val_loss: 0.0374 - val_accuracy: 0.9893 - lr: 6.3824e-04\n",
      "Epoch 39/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1242 - accuracy: 0.9615 - val_loss: 0.0407 - val_accuracy: 0.9877 - lr: 6.3824e-04\n",
      "Epoch 40/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1260 - accuracy: 0.9618 - val_loss: 0.0422 - val_accuracy: 0.9869 - lr: 6.3824e-04\n",
      "Epoch 41/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.1208 - accuracy: 0.9631 - val_loss: 0.0416 - val_accuracy: 0.9879 - lr: 6.1271e-04\n",
      "Epoch 42/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1211 - accuracy: 0.9632 - val_loss: 0.0391 - val_accuracy: 0.9886 - lr: 6.1271e-04\n",
      "Epoch 43/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1202 - accuracy: 0.9635 - val_loss: 0.0384 - val_accuracy: 0.9884 - lr: 6.1271e-04\n",
      "Epoch 44/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1196 - accuracy: 0.9634 - val_loss: 0.0407 - val_accuracy: 0.9894 - lr: 5.8820e-04\n",
      "Epoch 45/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1168 - accuracy: 0.9634 - val_loss: 0.0416 - val_accuracy: 0.9878 - lr: 5.8820e-04\n",
      "Epoch 46/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1196 - accuracy: 0.9636 - val_loss: 0.0407 - val_accuracy: 0.9876 - lr: 5.8820e-04\n",
      "Epoch 47/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1134 - accuracy: 0.9651 - val_loss: 0.0373 - val_accuracy: 0.9887 - lr: 5.6467e-04\n",
      "Epoch 48/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1098 - accuracy: 0.9664 - val_loss: 0.0389 - val_accuracy: 0.9889 - lr: 5.6467e-04\n",
      "Epoch 49/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1145 - accuracy: 0.9651 - val_loss: 0.0413 - val_accuracy: 0.9881 - lr: 5.6467e-04\n",
      "Epoch 50/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1148 - accuracy: 0.9651 - val_loss: 0.0385 - val_accuracy: 0.9897 - lr: 5.6467e-04\n",
      "Epoch 51/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1080 - accuracy: 0.9666 - val_loss: 0.0373 - val_accuracy: 0.9892 - lr: 5.4209e-04\n",
      "Epoch 52/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1103 - accuracy: 0.9661 - val_loss: 0.0362 - val_accuracy: 0.9898 - lr: 5.4209e-04\n",
      "Epoch 53/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1148 - accuracy: 0.9656 - val_loss: 0.0367 - val_accuracy: 0.9895 - lr: 5.4209e-04\n",
      "Epoch 54/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1083 - accuracy: 0.9679 - val_loss: 0.0356 - val_accuracy: 0.9894 - lr: 5.2040e-04\n",
      "Epoch 55/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1074 - accuracy: 0.9662 - val_loss: 0.0390 - val_accuracy: 0.9893 - lr: 5.2040e-04\n",
      "Epoch 56/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1124 - accuracy: 0.9667 - val_loss: 0.0374 - val_accuracy: 0.9893 - lr: 5.2040e-04\n",
      "Epoch 57/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1079 - accuracy: 0.9672 - val_loss: 0.0340 - val_accuracy: 0.9904 - lr: 4.9959e-04\n",
      "Epoch 58/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1057 - accuracy: 0.9676 - val_loss: 0.0374 - val_accuracy: 0.9893 - lr: 4.9959e-04\n",
      "Epoch 59/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1095 - accuracy: 0.9677 - val_loss: 0.0354 - val_accuracy: 0.9902 - lr: 4.9959e-04\n",
      "Epoch 60/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1069 - accuracy: 0.9671 - val_loss: 0.0354 - val_accuracy: 0.9901 - lr: 4.9959e-04\n",
      "Epoch 61/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1063 - accuracy: 0.9681 - val_loss: 0.0368 - val_accuracy: 0.9898 - lr: 4.7960e-04\n",
      "Epoch 62/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1036 - accuracy: 0.9689 - val_loss: 0.0363 - val_accuracy: 0.9896 - lr: 4.7960e-04\n",
      "Epoch 63/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1038 - accuracy: 0.9684 - val_loss: 0.0358 - val_accuracy: 0.9894 - lr: 4.7960e-04\n",
      "Epoch 64/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1036 - accuracy: 0.9677 - val_loss: 0.0349 - val_accuracy: 0.9895 - lr: 4.6042e-04\n",
      "Epoch 65/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1011 - accuracy: 0.9694 - val_loss: 0.0368 - val_accuracy: 0.9893 - lr: 4.6042e-04\n",
      "Epoch 66/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1000 - accuracy: 0.9705 - val_loss: 0.0343 - val_accuracy: 0.9898 - lr: 4.6042e-04\n",
      "Epoch 67/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0969 - accuracy: 0.9701 - val_loss: 0.0336 - val_accuracy: 0.9905 - lr: 4.4200e-04\n",
      "Epoch 68/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1011 - accuracy: 0.9692 - val_loss: 0.0336 - val_accuracy: 0.9904 - lr: 4.4200e-04\n",
      "Epoch 69/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.1009 - accuracy: 0.9689 - val_loss: 0.0375 - val_accuracy: 0.9901 - lr: 4.4200e-04\n",
      "Epoch 70/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0974 - accuracy: 0.9702 - val_loss: 0.0340 - val_accuracy: 0.9903 - lr: 4.4200e-04\n",
      "Epoch 71/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0960 - accuracy: 0.9716 - val_loss: 0.0316 - val_accuracy: 0.9906 - lr: 4.2432e-04\n",
      "Epoch 72/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0947 - accuracy: 0.9707 - val_loss: 0.0359 - val_accuracy: 0.9894 - lr: 4.2432e-04\n",
      "Epoch 73/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0943 - accuracy: 0.9707 - val_loss: 0.0343 - val_accuracy: 0.9901 - lr: 4.2432e-04\n",
      "Epoch 74/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0938 - accuracy: 0.9718 - val_loss: 0.0342 - val_accuracy: 0.9903 - lr: 4.0735e-04\n",
      "Epoch 75/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0925 - accuracy: 0.9715 - val_loss: 0.0337 - val_accuracy: 0.9896 - lr: 4.0735e-04\n",
      "Epoch 76/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0935 - accuracy: 0.9714 - val_loss: 0.0319 - val_accuracy: 0.9908 - lr: 4.0735e-04\n",
      "Epoch 77/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0925 - accuracy: 0.9718 - val_loss: 0.0333 - val_accuracy: 0.9902 - lr: 3.9106e-04\n",
      "Epoch 78/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0962 - accuracy: 0.9694 - val_loss: 0.0321 - val_accuracy: 0.9906 - lr: 3.9106e-04\n",
      "Epoch 79/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0900 - accuracy: 0.9720 - val_loss: 0.0329 - val_accuracy: 0.9900 - lr: 3.9106e-04\n",
      "Epoch 80/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0876 - accuracy: 0.9734 - val_loss: 0.0356 - val_accuracy: 0.9898 - lr: 3.9106e-04\n",
      "Epoch 81/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0942 - accuracy: 0.9709 - val_loss: 0.0332 - val_accuracy: 0.9902 - lr: 3.7541e-04\n",
      "Epoch 82/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0899 - accuracy: 0.9720 - val_loss: 0.0329 - val_accuracy: 0.9907 - lr: 3.7541e-04\n",
      "Epoch 83/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0912 - accuracy: 0.9717 - val_loss: 0.0314 - val_accuracy: 0.9908 - lr: 3.7541e-04\n",
      "Epoch 84/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0891 - accuracy: 0.9724 - val_loss: 0.0346 - val_accuracy: 0.9900 - lr: 3.6040e-04\n",
      "Epoch 85/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0885 - accuracy: 0.9736 - val_loss: 0.0340 - val_accuracy: 0.9908 - lr: 3.6040e-04\n",
      "Epoch 86/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0893 - accuracy: 0.9724 - val_loss: 0.0309 - val_accuracy: 0.9912 - lr: 3.6040e-04\n",
      "Epoch 87/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0909 - accuracy: 0.9721 - val_loss: 0.0307 - val_accuracy: 0.9920 - lr: 3.4598e-04\n",
      "Epoch 88/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0876 - accuracy: 0.9722 - val_loss: 0.0320 - val_accuracy: 0.9908 - lr: 3.4598e-04\n",
      "Epoch 89/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0889 - accuracy: 0.9724 - val_loss: 0.0313 - val_accuracy: 0.9908 - lr: 3.4598e-04\n",
      "Epoch 90/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0851 - accuracy: 0.9737 - val_loss: 0.0350 - val_accuracy: 0.9897 - lr: 3.4598e-04\n",
      "Epoch 91/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0855 - accuracy: 0.9739 - val_loss: 0.0344 - val_accuracy: 0.9910 - lr: 3.3214e-04\n",
      "Epoch 92/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0867 - accuracy: 0.9736 - val_loss: 0.0346 - val_accuracy: 0.9902 - lr: 3.3214e-04\n",
      "Epoch 93/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0844 - accuracy: 0.9751 - val_loss: 0.0346 - val_accuracy: 0.9908 - lr: 3.3214e-04\n",
      "Epoch 94/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0865 - accuracy: 0.9725 - val_loss: 0.0335 - val_accuracy: 0.9906 - lr: 3.1886e-04\n",
      "Epoch 95/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0859 - accuracy: 0.9746 - val_loss: 0.0320 - val_accuracy: 0.9907 - lr: 3.1886e-04\n",
      "Epoch 96/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0790 - accuracy: 0.9749 - val_loss: 0.0315 - val_accuracy: 0.9912 - lr: 3.1886e-04\n",
      "Epoch 97/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0818 - accuracy: 0.9744 - val_loss: 0.0346 - val_accuracy: 0.9902 - lr: 3.0610e-04\n",
      "Epoch 98/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0826 - accuracy: 0.9744 - val_loss: 0.0293 - val_accuracy: 0.9916 - lr: 3.0610e-04\n",
      "Epoch 99/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0848 - accuracy: 0.9739 - val_loss: 0.0300 - val_accuracy: 0.9912 - lr: 3.0610e-04\n",
      "Epoch 100/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0840 - accuracy: 0.9737 - val_loss: 0.0317 - val_accuracy: 0.9908 - lr: 3.0610e-04\n",
      "Epoch 101/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0835 - accuracy: 0.9742 - val_loss: 0.0295 - val_accuracy: 0.9913 - lr: 2.9386e-04\n",
      "Epoch 102/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0832 - accuracy: 0.9745 - val_loss: 0.0296 - val_accuracy: 0.9915 - lr: 2.9386e-04\n",
      "Epoch 103/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0844 - accuracy: 0.9748 - val_loss: 0.0289 - val_accuracy: 0.9912 - lr: 2.9386e-04\n",
      "Epoch 104/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0840 - accuracy: 0.9747 - val_loss: 0.0287 - val_accuracy: 0.9912 - lr: 2.8210e-04\n",
      "Epoch 105/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0804 - accuracy: 0.9755 - val_loss: 0.0293 - val_accuracy: 0.9916 - lr: 2.8210e-04\n",
      "Epoch 106/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0843 - accuracy: 0.9750 - val_loss: 0.0288 - val_accuracy: 0.9923 - lr: 2.8210e-04\n",
      "Epoch 107/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0793 - accuracy: 0.9750 - val_loss: 0.0305 - val_accuracy: 0.9924 - lr: 2.7082e-04\n",
      "Epoch 108/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0775 - accuracy: 0.9759 - val_loss: 0.0295 - val_accuracy: 0.9917 - lr: 2.7082e-04\n",
      "Epoch 109/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0790 - accuracy: 0.9758 - val_loss: 0.0299 - val_accuracy: 0.9919 - lr: 2.7082e-04\n",
      "Epoch 110/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0826 - accuracy: 0.9754 - val_loss: 0.0299 - val_accuracy: 0.9917 - lr: 2.7082e-04\n",
      "Epoch 111/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0769 - accuracy: 0.9759 - val_loss: 0.0305 - val_accuracy: 0.9918 - lr: 2.5999e-04\n",
      "Epoch 112/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0789 - accuracy: 0.9762 - val_loss: 0.0300 - val_accuracy: 0.9918 - lr: 2.5999e-04\n",
      "Epoch 113/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0777 - accuracy: 0.9759 - val_loss: 0.0299 - val_accuracy: 0.9920 - lr: 2.5999e-04\n",
      "Epoch 114/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0800 - accuracy: 0.9756 - val_loss: 0.0285 - val_accuracy: 0.9915 - lr: 2.4959e-04\n",
      "Epoch 115/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0766 - accuracy: 0.9756 - val_loss: 0.0292 - val_accuracy: 0.9921 - lr: 2.4959e-04\n",
      "Epoch 116/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0806 - accuracy: 0.9757 - val_loss: 0.0285 - val_accuracy: 0.9917 - lr: 2.4959e-04\n",
      "Epoch 117/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0761 - accuracy: 0.9759 - val_loss: 0.0292 - val_accuracy: 0.9918 - lr: 2.3960e-04\n",
      "Epoch 118/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0759 - accuracy: 0.9775 - val_loss: 0.0285 - val_accuracy: 0.9920 - lr: 2.3960e-04\n",
      "Epoch 119/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0738 - accuracy: 0.9769 - val_loss: 0.0298 - val_accuracy: 0.9915 - lr: 2.3960e-04\n",
      "Epoch 120/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0759 - accuracy: 0.9765 - val_loss: 0.0283 - val_accuracy: 0.9923 - lr: 2.3960e-04\n",
      "Epoch 121/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0744 - accuracy: 0.9770 - val_loss: 0.0285 - val_accuracy: 0.9919 - lr: 2.3002e-04\n",
      "Epoch 122/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0743 - accuracy: 0.9762 - val_loss: 0.0270 - val_accuracy: 0.9926 - lr: 2.3002e-04\n",
      "Epoch 123/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0743 - accuracy: 0.9774 - val_loss: 0.0270 - val_accuracy: 0.9926 - lr: 2.3002e-04\n",
      "Epoch 124/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0776 - accuracy: 0.9768 - val_loss: 0.0278 - val_accuracy: 0.9920 - lr: 2.2082e-04\n",
      "Epoch 125/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0746 - accuracy: 0.9767 - val_loss: 0.0295 - val_accuracy: 0.9910 - lr: 2.2082e-04\n",
      "Epoch 126/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0708 - accuracy: 0.9773 - val_loss: 0.0302 - val_accuracy: 0.9923 - lr: 2.2082e-04\n",
      "Epoch 127/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0744 - accuracy: 0.9771 - val_loss: 0.0293 - val_accuracy: 0.9915 - lr: 2.1199e-04\n",
      "Epoch 128/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0743 - accuracy: 0.9770 - val_loss: 0.0292 - val_accuracy: 0.9915 - lr: 2.1199e-04\n",
      "Epoch 129/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0731 - accuracy: 0.9774 - val_loss: 0.0290 - val_accuracy: 0.9920 - lr: 2.1199e-04\n",
      "Epoch 130/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0728 - accuracy: 0.9770 - val_loss: 0.0274 - val_accuracy: 0.9923 - lr: 2.1199e-04\n",
      "Epoch 131/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0765 - accuracy: 0.9761 - val_loss: 0.0286 - val_accuracy: 0.9920 - lr: 2.0351e-04\n",
      "Epoch 132/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0738 - accuracy: 0.9768 - val_loss: 0.0284 - val_accuracy: 0.9919 - lr: 2.0351e-04\n",
      "Epoch 133/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0718 - accuracy: 0.9777 - val_loss: 0.0281 - val_accuracy: 0.9917 - lr: 2.0351e-04\n",
      "Epoch 134/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0725 - accuracy: 0.9774 - val_loss: 0.0275 - val_accuracy: 0.9919 - lr: 1.9537e-04\n",
      "Epoch 135/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0724 - accuracy: 0.9777 - val_loss: 0.0289 - val_accuracy: 0.9918 - lr: 1.9537e-04\n",
      "Epoch 136/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0703 - accuracy: 0.9784 - val_loss: 0.0290 - val_accuracy: 0.9918 - lr: 1.9537e-04\n",
      "Epoch 137/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0728 - accuracy: 0.9770 - val_loss: 0.0290 - val_accuracy: 0.9912 - lr: 1.8755e-04\n",
      "Epoch 138/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0719 - accuracy: 0.9776 - val_loss: 0.0286 - val_accuracy: 0.9914 - lr: 1.8755e-04\n",
      "Epoch 139/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0710 - accuracy: 0.9783 - val_loss: 0.0277 - val_accuracy: 0.9913 - lr: 1.8755e-04\n",
      "Epoch 140/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0685 - accuracy: 0.9788 - val_loss: 0.0282 - val_accuracy: 0.9916 - lr: 1.8755e-04\n",
      "Epoch 141/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0705 - accuracy: 0.9774 - val_loss: 0.0276 - val_accuracy: 0.9918 - lr: 1.8005e-04\n",
      "Epoch 142/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0707 - accuracy: 0.9780 - val_loss: 0.0284 - val_accuracy: 0.9919 - lr: 1.8005e-04\n",
      "Epoch 143/200\n",
      "1500/1500 [==============================] - 16s 11ms/step - loss: 0.0706 - accuracy: 0.9770 - val_loss: 0.0267 - val_accuracy: 0.9923 - lr: 1.8005e-04\n",
      "Epoch 144/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0716 - accuracy: 0.9777 - val_loss: 0.0275 - val_accuracy: 0.9920 - lr: 1.7285e-04\n",
      "Epoch 145/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0673 - accuracy: 0.9784 - val_loss: 0.0278 - val_accuracy: 0.9918 - lr: 1.7285e-04\n",
      "Epoch 146/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0696 - accuracy: 0.9781 - val_loss: 0.0280 - val_accuracy: 0.9923 - lr: 1.7285e-04\n",
      "Epoch 147/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0682 - accuracy: 0.9782 - val_loss: 0.0291 - val_accuracy: 0.9922 - lr: 1.6593e-04\n",
      "Epoch 148/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0682 - accuracy: 0.9786 - val_loss: 0.0267 - val_accuracy: 0.9918 - lr: 1.6593e-04\n",
      "Epoch 149/200\n",
      "1500/1500 [==============================] - 16s 10ms/step - loss: 0.0692 - accuracy: 0.9786 - val_loss: 0.0276 - val_accuracy: 0.9918 - lr: 1.6593e-04\n",
      "Epoch 150/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0689 - accuracy: 0.9784 - val_loss: 0.0279 - val_accuracy: 0.9923 - lr: 1.6593e-04\n",
      "Epoch 151/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0710 - accuracy: 0.9786 - val_loss: 0.0273 - val_accuracy: 0.9924 - lr: 1.5930e-04\n",
      "Epoch 152/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0679 - accuracy: 0.9789 - val_loss: 0.0272 - val_accuracy: 0.9919 - lr: 1.5930e-04\n",
      "Epoch 153/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0709 - accuracy: 0.9785 - val_loss: 0.0283 - val_accuracy: 0.9920 - lr: 1.5930e-04\n",
      "Epoch 154/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0668 - accuracy: 0.9789 - val_loss: 0.0262 - val_accuracy: 0.9925 - lr: 1.5292e-04\n",
      "Epoch 155/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0642 - accuracy: 0.9795 - val_loss: 0.0286 - val_accuracy: 0.9916 - lr: 1.5292e-04\n",
      "Epoch 156/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0706 - accuracy: 0.9781 - val_loss: 0.0265 - val_accuracy: 0.9926 - lr: 1.5292e-04\n",
      "Epoch 157/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0634 - accuracy: 0.9802 - val_loss: 0.0272 - val_accuracy: 0.9925 - lr: 1.4681e-04\n",
      "Epoch 158/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0653 - accuracy: 0.9791 - val_loss: 0.0269 - val_accuracy: 0.9917 - lr: 1.4681e-04\n",
      "Epoch 159/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0675 - accuracy: 0.9790 - val_loss: 0.0286 - val_accuracy: 0.9918 - lr: 1.4681e-04\n",
      "Epoch 160/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0657 - accuracy: 0.9800 - val_loss: 0.0261 - val_accuracy: 0.9917 - lr: 1.4681e-04\n",
      "Epoch 161/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0265 - val_accuracy: 0.9921 - lr: 1.4093e-04\n",
      "Epoch 162/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0636 - accuracy: 0.9795 - val_loss: 0.0270 - val_accuracy: 0.9917 - lr: 1.4093e-04\n",
      "Epoch 163/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0665 - accuracy: 0.9793 - val_loss: 0.0271 - val_accuracy: 0.9915 - lr: 1.4093e-04\n",
      "Epoch 164/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.0273 - val_accuracy: 0.9920 - lr: 1.3530e-04\n",
      "Epoch 165/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0645 - accuracy: 0.9798 - val_loss: 0.0273 - val_accuracy: 0.9921 - lr: 1.3530e-04\n",
      "Epoch 166/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0646 - accuracy: 0.9806 - val_loss: 0.0279 - val_accuracy: 0.9918 - lr: 1.3530e-04\n",
      "Epoch 167/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0640 - accuracy: 0.9799 - val_loss: 0.0274 - val_accuracy: 0.9919 - lr: 1.2989e-04\n",
      "Epoch 168/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0652 - accuracy: 0.9800 - val_loss: 0.0268 - val_accuracy: 0.9924 - lr: 1.2989e-04\n",
      "Epoch 169/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0627 - accuracy: 0.9801 - val_loss: 0.0278 - val_accuracy: 0.9916 - lr: 1.2989e-04\n",
      "Epoch 170/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0673 - accuracy: 0.9793 - val_loss: 0.0264 - val_accuracy: 0.9920 - lr: 1.2989e-04\n",
      "Epoch 171/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0611 - accuracy: 0.9806 - val_loss: 0.0269 - val_accuracy: 0.9923 - lr: 1.2469e-04\n",
      "Epoch 172/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0680 - accuracy: 0.9786 - val_loss: 0.0260 - val_accuracy: 0.9925 - lr: 1.2469e-04\n",
      "Epoch 173/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0661 - accuracy: 0.9790 - val_loss: 0.0258 - val_accuracy: 0.9926 - lr: 1.2469e-04\n",
      "Epoch 174/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0634 - accuracy: 0.9796 - val_loss: 0.0259 - val_accuracy: 0.9926 - lr: 1.1970e-04\n",
      "Epoch 175/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0616 - accuracy: 0.9804 - val_loss: 0.0271 - val_accuracy: 0.9926 - lr: 1.1970e-04\n",
      "Epoch 176/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0653 - accuracy: 0.9796 - val_loss: 0.0272 - val_accuracy: 0.9918 - lr: 1.1970e-04\n",
      "Epoch 177/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0636 - accuracy: 0.9800 - val_loss: 0.0274 - val_accuracy: 0.9914 - lr: 1.1491e-04\n",
      "Epoch 178/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0626 - accuracy: 0.9804 - val_loss: 0.0268 - val_accuracy: 0.9914 - lr: 1.1491e-04\n",
      "Epoch 179/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0625 - accuracy: 0.9802 - val_loss: 0.0273 - val_accuracy: 0.9923 - lr: 1.1491e-04\n",
      "Epoch 180/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0622 - accuracy: 0.9802 - val_loss: 0.0271 - val_accuracy: 0.9920 - lr: 1.1491e-04\n",
      "Epoch 181/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0619 - accuracy: 0.9808 - val_loss: 0.0284 - val_accuracy: 0.9918 - lr: 1.1032e-04\n",
      "Epoch 182/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0625 - accuracy: 0.9799 - val_loss: 0.0272 - val_accuracy: 0.9918 - lr: 1.1032e-04\n",
      "Epoch 183/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0646 - accuracy: 0.9802 - val_loss: 0.0265 - val_accuracy: 0.9922 - lr: 1.1032e-04\n",
      "Epoch 184/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 0.0278 - val_accuracy: 0.9915 - lr: 1.0591e-04\n",
      "Epoch 185/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0618 - accuracy: 0.9807 - val_loss: 0.0271 - val_accuracy: 0.9916 - lr: 1.0591e-04\n",
      "Epoch 186/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0622 - accuracy: 0.9804 - val_loss: 0.0273 - val_accuracy: 0.9921 - lr: 1.0591e-04\n",
      "Epoch 187/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0270 - val_accuracy: 0.9926 - lr: 1.0167e-04\n",
      "Epoch 188/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.0277 - val_accuracy: 0.9920 - lr: 1.0167e-04\n",
      "Epoch 189/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0609 - accuracy: 0.9812 - val_loss: 0.0271 - val_accuracy: 0.9918 - lr: 1.0167e-04\n",
      "Epoch 190/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0628 - accuracy: 0.9803 - val_loss: 0.0280 - val_accuracy: 0.9918 - lr: 1.0167e-04\n",
      "Epoch 191/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0602 - accuracy: 0.9806 - val_loss: 0.0260 - val_accuracy: 0.9925 - lr: 9.7602e-05\n",
      "Epoch 192/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0613 - accuracy: 0.9804 - val_loss: 0.0269 - val_accuracy: 0.9924 - lr: 9.7602e-05\n",
      "Epoch 193/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0620 - accuracy: 0.9806 - val_loss: 0.0280 - val_accuracy: 0.9923 - lr: 9.7602e-05\n",
      "Epoch 194/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0590 - accuracy: 0.9816 - val_loss: 0.0271 - val_accuracy: 0.9923 - lr: 9.3698e-05\n",
      "Epoch 195/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0609 - accuracy: 0.9806 - val_loss: 0.0256 - val_accuracy: 0.9925 - lr: 9.3698e-05\n",
      "Epoch 196/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0619 - accuracy: 0.9808 - val_loss: 0.0260 - val_accuracy: 0.9925 - lr: 9.3698e-05\n",
      "Epoch 197/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0596 - accuracy: 0.9805 - val_loss: 0.0263 - val_accuracy: 0.9923 - lr: 8.9950e-05\n",
      "Epoch 198/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0613 - accuracy: 0.9808 - val_loss: 0.0258 - val_accuracy: 0.9926 - lr: 8.9950e-05\n",
      "Epoch 199/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0258 - val_accuracy: 0.9927 - lr: 8.9950e-05\n",
      "Epoch 200/200\n",
      "1500/1500 [==============================] - 15s 10ms/step - loss: 0.0611 - accuracy: 0.9811 - val_loss: 0.0261 - val_accuracy: 0.9923 - lr: 8.9950e-05\n"
     ]
    }
   ],
   "source": [
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    ")\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=5000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True)\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.9,\n",
    "                            patience=5, min_lr=0.00001)\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dense(units=10, activation = 'softmax'))\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=lr_schedule), metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(datagen.flow(x_train_augmented,y_train_augmented),  epochs=200, batch_size=256, validation_data=(x_val, y_val), callbacks=[reduce_lr])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9375854a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f65440e050>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD6CAYAAACoCZCsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAzYklEQVR4nO3deXxddZ3w8c83N/vSJG3SNE26N11ZCoQCsgiWpYBYYAYtLnQQBnkEB2Z0BgYfR32cGRkdcXge0AqKgCKIClpnyiYiiGxNoaULXdJ0S5NmbbNv997v88fvJNzcJs1tm+SmPd/363Vf957fWe7vnNz8vuf8lnNEVTHGGOM/CfHOgDHGmPiwAGCMMT5lAcAYY3zKAoAxxviUBQBjjPEpCwDGGONTQwYAEXlERGpFZOMg80VE/q+IlIvI+yJyesS8pSKy1Zt3d0T6eBF5SUS2e++5w7M7xhhjYiVDjQMQkQuAVuBxVT1pgPlXAF8CrgDOAu5X1bNEJABsAy4BKoE1wPWqullEvgM0quq9XmDIVdW7hspsXl6eTp8+/Yh20Bhj/G7t2rX1qpofnZ441Iqq+pqITD/MIstwwUGBt0QkR0QKgelAuapWAIjIU96ym733C731HwP+BAwZAKZPn05ZWdlQixljjIkgIrsHSh+ONoAiYG/EdKWXNlg6QIGqVgN47xOHIR/GGGOOwHAEABkgTQ+TfmQbF7lFRMpEpKyuru6IM2eMMWZgwxEAKoEpEdPFQNVh0gFqvGoivPfawTauqg+paqmqlubnH1KFZYwx5igNRwBYBdzg9QY6G2jyqnXWACUiMkNEkoHl3rK966zwPq8AfjcM+TDGGHMEhmwEFpEncQ22eSJSCXwdSAJQ1ZXAalwPoHKgHbjRmxcUkduBF4AA8IiqbvI2ey/wtIjcBOwBrhvGfTLGGBODIbuBjiWlpaVqvYCMMebIiMhaVS2NTreRwMYY41NDVgEZY45dOKw0tncTVmViVuqwbFNVCYaVpEAC+5s6Wbv7AACLpuZQlJM2LN9xJHnp7AmTlhyIafmWzh4a27qZkptOQoLrMFjf2kVnT4ji3HQa27pZs6uRjORETpuaQ0bK0RVVqkp9azd5mcmIfNgxsam9h/K6Vlq7gnQHw3QHwyhKbnoy58yc0Jeno9HRHWLt7gPMK8wiLzOl37ztNS00d/aQkhggNSlAalICIkJtcycdPSESExKYmJVCVzDM7oY2dje0k5GSyPkleUwZn37UeRqMBQDjKxv3NfGj1yq48uRJLD2p8Ki2EQ4r7+09QFFOOpOyU/vSqps7qWvpomBcCpPGufSd9W08+94+nnh7D41t3YjAlScXUpybTl1LFzPy0kkKJHCgvYeD7d0caO+mOxjm3Nl5tHeHeHVbHfMmZVGcm05NcydVBztISw5QOn08T769h+21LcwvHMfmqmaCYVedKwIXzZ3I1z6+gN+sreQX7+zh+sVTuKAkn8a2bl7cXMO6vQfZd7CDKblpTM5JIzstiRl5GSQmJLC7sY1xqUnkpCeRmCB8ZHYei4pzqG7uRIBQWNle28L2mlb2NLbT1NHDe3vc9mbkZVAyMZOUpABvVTTQ1N5DdnoSJ00ex6z8TMIKf9xSw66GdgAmZqVwSnE2jW3drNt7EIBPnDqZ17bX09jWDUBeZgqfOWsqHT0hUhMTCCQk8PbOBjJSEvnIrAlMHZ/OtppWXi+v42B7D9lpSSycPI6WziDv7Gykor6N06fmsGR+AW/vbGRLdTO1LV2D/n3nTcri+sVTOXP6eETg8Td3sWpdFZNz0phTkMW0Cel0B8PsqGulor6NJfMKuHBuPg1tXfxhcy1/3FLrFebCWTPHU5yTTmpSApuqminzgvTRWPnZM1h60qSjXn8g1gZgjlprV5C0pACBozhbauroYU9DO1mpiRTnppEYSKCjO0R5bStJicK8SeP6lg2Fte87/rS1lu5gmLNmTqC8tpUJGclMz8voW7azJ0TZrgNU1LfSHQxz2cJJpCYF+OlfdvL2zkbW7j5AgkBY4apTJ1OQlcInFk2mZGIW337uAwrGpfKJUyfzZkUDXcEwEzKSaesK8vbORjZXNfP582bwRnk9z7y3D4DpE9JZODmbNbsa+xUqyYEEUpISaOkMIgIXzy/gvNl5VDd18rM3d9EdCpObnty3TlJAyElPJjc9ibBCeW0rACcVjWNnXRtt3SGyUhMpzE6lobWbhrZuinPTuHh+ARv2NXFqcQ7XnFaECLy4uYaf/mUnrV1BVN02NlU10/uvnpOexDkzJzA5J429je3UtnRxsL2bvQc6CIWVwuxUWjqDtHYF+/YnKSD0hA4tK3LTkxiXlsTcgizmFY7jg+pmdje00doZ5Izp45mc4/K73gs43cEw58yawEdm5TEuLZE/b6tnV4MLOGfNHE9TRw8/f2s3Jxdlc/fl8+kMhvjBK+Ws2XWA5MQEekJhVGFB4TiaO3uoPNDRl5cFheOYlJ1KbUsnW/e3kJ2WzLxJWZw+NYcn1+ylrqWLOQWZnFKcQ8nETGZPzCQnPYnkQIDkxAQSBDZWNfGDV3aw3Tv+vfv+8VMm09IZZHttC3sb20lLCjA5J42i3DRe317fF3zzMlNYelIBH50zkXd2NvD2zkaqmzrpCbnf0qfPmkbJxEw6ekJ0eq+wukCYkZJITyjM/qZOkhMTmD4hg2kT0qlv7eLVbfVcvWgyE6KuKGI1WBuABQAf6QqGCIiQGBi86WdvYzu7Gto4c/p4/rS1jh11rZxclE1+VgppSe6yNS0pwMtbavjabzcyuyCL2y6cxf0vb6e2pYuinDROKc5m7qQsCrNTKcxOIzkxgc6eEHmZKVQeaOfZ9/bxm7X76OgJAZCeHCA3PZmqpo6+QuoLH51JQITnN+1nd0M78wuzmJGXye/XVx2S59On5jCnIIvqpk7e3tlAZ0+4b15igpCcmEBXMMxpU3I4rySPz509jQdeKec3ayvpDIZRVaZPyKC8rpXB/h2yUhKZlJ3aVzB88cJZjM9I5q2KRjZVuQL4/Dl5TMxKZX9TB5UHO2jvCjFnUhYXzc2nOPfDy/fOnhCBBCEpkEBbVxAFMpID/aoo9jS0k5AAxbnp9ITCdAXDZHrVIMFQmG01rcyamEFK4sBVLtVNHXz3+a2cNjWHz549jd0N7ew72EFqUgKnFOeQNMBvoLMnhCp91TjhsNLaHeR/3q+moq6VGXmZiLgRnrP7CtDkgQ/YIFS1334OpLalkwkZKX1BX1Vp7QqSmZJIMKx9x0JVqW3poupgB/lZKf2OcfT3dPaEaO0KHlIlM5hd9W1s2NdEWJXTp+b2q36J3nZNcye7G9oZl5ZIycSsozohGmkWAE5gTe093PDTd7hobj53LCnp9+PcUddKS2eQvY3tfPP3myjKSePnN59FVmoSHd0hfrV2L7sb2inMTuXc2Xnc8Mg71LV0EUgQQuHD/zZOLc5mR10brV1BJmencn5JPrsa3D9Oe3do0PWSExP4xKmTuXj+RFo6g2yqaqahrZvZ+ZnMKcjk1W11PLVmLyJwQUk+cydl8fzG/expbOf2i2azeMZ41u89SElBFhX1rbywqYZ9BzoYl5bIBSX5XDAnj5OKsukOhvnpX3bR1NHDFy+cxcz8zEPycrC9m7//5Tre2NHA/ctPY3JOKm/uaODc2XlMzEqhoa2b9OQAhdlpBBKEJ9/ZQ3pygGtPLz76P5gxo8wCwAmkoq6VR9/YxRs7GrjipEnsamhnlXdm/IULZvKVy+aypbqFbz/3AW/saOhbb05BJhV1bZxSnM2nz5rGj/9cwZb9LaQmJfSdNY/PSOaeK+azqaqJxdPHc86sCWyuauZgR493yRqmoydETloSV59WxO6GNl7aXMOnz5pKVmoS4Kps6lq6qGrqoPqgu/xNTUqgrrWbcamJfGzexL5lB/PungPkZaQwdYI78+q9NB6JhjBVpb07dNQNjcaMdRYAxrA1uxp5bsN+qps6+F8XzuKU4hw+qG7mO89vYX1lEwkizCnI5PSpueSkJ3HfS9sIqzJv0ri+hrM7Ly6hrqWLJ97eQ1FOGvubOxmfkcznz51BycRMekJhLl5QwIubavjyr9bR2RMmJz2J739yERfOzeftnY088fYebv3oTBZOzo7vATHGDCsLAKOorSvIz97aTUVdK/942Tzys/rXO6oqG/Y1caC9h7JdjTzwSjnJgQTSkgO0dgaZkZfB9tpWstOSuOLkSYTDrnFqy/4WQmHl9Kk5/OAzZzApO5Vfle1lfeVBvnHVQgIJwh+31PL9P2xjYWE291w5n+y0Q8+0u4NhdjW0MTEr5YjrcI0xxx8LAKPklS21/OOv36e+1dWj56Ync8M505g3KQsRYf3eg7ywaX+/XgZ/dXox/3r1SXQFQ/zb/3xAdVMn55fksfzMqWSnf1iAt3cH2VnfxpyCrAEb8YwxZiAWAEZIc2cPtc2dFOemc+9zW3j0jV3Mm5TFv197MunJAf75mQ2s23uwr3dJIEE4Y2ou155eRElBJkmBBE4uyh6yZ4QxxhytwQKAtXodhRc27WdHXSvzC8dx16/fp7ali/TkAO3dIW48dzp3LZ1HapLrSvfsF8+lubOHXfVtqML0vIwBq2WMMWa0WQA4Qv/9fhV/9+R79PaQLM5N418+voD3Kw+ybFERF8079OFm41KTOKU4Z3QzaowZ+1Sh8yCk5cbl6y0AxEhV+cU7e/j67zZxxrRc/vXqk1m39wAXzy846tF5xphh1NkMqd4I8vZGV6gOVLWqCsFOSDqK+yW1N8K+d2HG+ZDo/d93t0NjBbTVQf486G6FbS9AyaUuDy99DaaeA6d9zi2TnOG+u3o9vPg12PMGnHObW761FvLnujzWbYW6LdBaA6FuOPcOKFh49MdnANYGcBhv7mjgibd3s77yIIKwp7GdC+bk88CnT2PcEP3YjTFHKRSEQCIEu+D3d8Dk02DxLa4wr9kEW1bDmTdB+ni3TEISvPxN+Mt/QcllrrCseAWKF8OcS6Flvyukc6bASX/lttlYAX/7CmR7jylv3AmvfReq3oMz/sYV0hWvwq4/gyTA+Jnufe87EOyACbNh1hKoXAP734dw8ND9SExzAaClGlBIznTBASCQAqEuSM1xweSD3w98LCQAGfmQmAzLfuCWPQrWCDyEcFipaemkMNudFTS0dnHBd14hLTnAWTMnoKosmpLDzefNPKY7BRpz3At2QdU6mDj/wzPuobQ3uoJQApA73Z09t1TDvrXQ0wGFi+DgHtj0LGz4FZy63BXCb/3ArT/lbFfobnjaFfAZEyFzItRshNRs6GyC2ZfAvjJA4NTrYfPvoLnSFcLJmdBUCSgkprp8TDoJzrjRfWf5SxBIhrw5rkAHV/DOuAASEuHALtAwTFwA086FP33bBZaiM2DKYph0MqRPcPlRhZkfhT98053Ff/IxaNgBu15z6/e0Q8cB97nkMsiY4I5nR6P7zrqtLthMnA/jZ7nC/xhZADiMrmCIO59ax3Mb9/PZs6dy19J5/L8/lvPjP1fw4t9fwOyJWcP+ncaMOV0trqDOmeoKvE3Putc5t7kCubka/vw9WP+kO5PNmwPXPuzOggsWwrSPuDPrt1ZC+R9cQZ+W4wrKPW+BercHkQAEklw1TLSkdFddsuNlN116kysI33nIff/sj7m0177rzrqnnwfNVa4QPn0FhHrceonJEA654JLi3QKkdgusfRRO/ZQrkH9zk0vPnASnfRbOvBmyJrmrgECy26fBeuepuu0HhqhFVx18G6PomAKAiCwF7sc92vHHqnpv1Pxc4BFgFtAJfF5VN4rIXOCXEYvOBP5FVf9LRL4B/C1Q5827R1VXHy4fIxUAbnm8jBc31/CxeRN5ZWstWSmJdAXDXHlyIfd9atGwf58xRyUcgt/c7ArTRZ+GuVe4gm7HH91ZaUoWPPdP7ox34TWQMs4VxLvfgMwCVwWSmOKmA8kw8yJX6KXlwPu/hBf/N7Q3uHkhdytmsgrdmfrMC916GoaTPwnFpfCHb0BX84f5Kyp1Z/QJiTDrIlfw97S7M/SZF8KkU1wBXb/VFcw502DyIlcfXrXOBZ6iM1yBveYnsPNVuOZHR1dXH4sdf4S08S5fCSf2uJqjDgAiEgC2AZcAlbiHvV+vqpsjlvku0Kqq3xSRecCDqrpkgO3sA85S1d1eAGhV1f+MdSdGIgDsaWjngu++wt8tKeEfLpnD+5UH+dGrFazdfYCnv3BO371ojBk2e9dA015XfTL1I676YtvzUFnmziiLznCFac5Ud9bcVu8K0/d+Dut/AcVnuoJWw/23G0hx1SYadj1LwBXGU85y39G0F7pa3frhHteYmTLO5aNpr6szP+WT7ux//ExX/ZEzFZ79Aux4xV0FnHUrjJ/htr1/g6tmmf8JVzWz9TlYcDUs/lt3Jm3GjGMZB7AYKFfVCm9DTwHLgM0RyywAvg2gqltEZLqIFKhqTcQyS4Adqrr7aHdiJLy4eT8Af+3d3fGU4hwe/Mzp8cySiTdVV82RN8ed6Qa7oPp9aNrjzrQPV7ipwsHdrsAOdsI7D7veHtPPc4XqvrWusO+VmOZVhSik57mCee2jg2///K/Akq+53iK7/gzdba6gXvck1G6Gy//DndXWbIKeNsifD5n5H64fDkGCdwvp2i3wx2+5s/HL/h3mfXzgM+G//ql7j67KmHSyewEUngKX/uvg+TZjUiwBoAjYGzFdCZwVtcx64FrgdRFZDEwDioHIALAceDJqvdtF5AagDPiyqh7yuBwRuQW4BWDq1KkxZDc2D722g7NnTuDFzTXMm5RlZ/onulCPq3ceSDjkGv5aalzPkm3Pu7rurEK49XV4fJlr3ANAXFVKcpar5pi9xBW42553vUZqNvavFknNhmnnufkdB9x6F3/TdflrqYbtL7r1F17tAo6qq0ffV+a6/0mCCwxZBZA9FfJmu+1mTnQ9Wnpd9M/996n4jIH3tbfwB5g4D5Y/MfSxGwN12GZkxFIFdB1wmare7E1/Dlisql+KWGYcro3gNGADMA+4WVXXe/OTgSpgYe9VgYgUAPWAAt8CClX184fLy3BVAbV2BTnp6y+Qk55Ec0cPt180m3+4dO4xb9fESbALXrjHFaQf++qh89/9Gaz+RzjlOrj8u5AU8UzeziZ4eoXrNhhp9iWuZ8i4ImjeBx//L1dXXP4HaNzh+nPv/LM7YwdAoOh015tl0skuSKi6xslU7+6qIa+r4FANh8YMs2OpAqoEpkRMF+MK8z6q2gzc6H2RADu9V6/LgXcjq4QiP4vIw8B/x5CXYVF5wD2P9GC7++e9dKHVV44p0T0nWmsB+bAqI9jlCuDsYlcF8uT1rsEQYPbF7iy+frvrUvfmA7D5t26AzruPw67XXf/tcA8c3OvO2Nsb4LJvu7ry1hrXP3v+Mvjt/4L3n4KPfAlKb3Tbjzyz7jjg6sFba13Pld4+5YOxgt+MMbH8ItcAJSIyA9eIuxz4dOQCIpIDtKtqN3Az8JoXFHpdT1T1j4gUqmq1N3kNsJFRUtnoniP6b9ecREtnkIWTY+zLbEZWqAf+++/dKMqLv+6qSTY+40ZShroha7Lr6XJwtwsCN/wWdr7mCv8r73PVNr++0QWH3l4sSRlw4T1wwVdcdctbP3SNqcnproFz6tlukNH08w7Nz9Jvw5Qz3QjOgaTluvp3Y45TQwYAVQ2KyO3AC7huoI+o6iYRudWbvxKYDzwuIiFc4/BNveuLSDquB9EXojb9HRFZhKsC2jXA/BHTewVw2cJJMT8j1AyT7S/Bq99xZ+/zroSF17qGx+42VxVT/hJMKIHf3fbhOnOWuj7mtR+45WYvcT1OVn3J1duf8ik3MjQjD56+wXWPPOd2N/Bn1sc+vHKYe7l7xdo3O3286yZpzAkqpmtSr3/+6qi0lRGf3wRKBlm3HZgwQPogp1Ujr/KAezj2hAx7GMqICQVdf++8OR82vr70dTdcP3e663a46Rl4+0eu6+H6J90AnKvuh9NugG3PuUbSzEkuUEQX2HMuc42ziWmw5F9c2oJlcOdGF1wOV8Bbo6YxgE9vBld5oIPi3HS7B/+RCIfcKNHILoWRQsEPe5hsehZe+TdoKHfD40++zlWX/OW/3GjNK77r7t+y/kn447/C6q+44fmfegLmXeG2Me/Kw+dn5oVwybdcT53siAe050wZdBVjTH/+DAAH2ynOHaHRhSeqZ291g34++2tX791U6erqt70Ae992A49yZ7gCeOdrMHGh63Gz5003qjPc4/qZf/z7HwaK0z7jRrQ2V7mrhMxDb6V9WOf+3bDvpjF+4s8AcKCDRVNy4p2NsUHVNYx2tbiG0oSAG5b/9Ocgb67ray7iRnomZ8KTn4bcaR/2i8+Z5vqwZxa4wn7/Bjcg6Owvum2ddYsbFFX+B6++P9D/+0WG7j1jjBkRvgsALZ09HGzvoTjXBn7R0wm/vdVV2QBUr3ONpq/8m6uSqdvq5oPr2778F/DUZ9ztAy75lquHz5szdJ16lnezLWPMmOKrALBlfzNdPe7+Kb6vAgp2ubP87S+5kalJ6fD8XbB1tRtxumKVa6ytXONGsZ76addt8tY/xzvnxphh4psA0NLZw8f/7+vkZ7lunyf8FUBnk6uzb6tzA5Y6Drp3DXtPG/rA3fTrqvvdAzAATv5rd1+YjLwPn3Y0ZbF7GWNOOL4JAFUHOwmGleomdw/yE/oK4OAe+Plfu26Y4O4SmT7ePX0oIdF7sMVC+NjXXKHfK318XLJrjIkP3wSA/c2u4D9zei7VTZ3H/xgAVXf3x6p17j7t255zBX1qNjRsd7cF/uwzbgDVSN1P3RhzXPNNAKjxzvzv++QiJuekHb9jADqb3SPz1j764aPrUsa5BtmERFfNM/dy1+g6YVZcs2qMGdt8EwB6rwAmjkshcDw907etAd573DXCdjbBTy5xfe4LToYr/tM91Sl3ut1ozBhzxHxTauxvdtU+KYmBoReOh+52d2Y/70rXQ+fdx93j9NY/BW21sP6Xrg99QgBuesk91el4vYoxxowJ/gkATZ0UjEsdesF4+cPX3YOvX/iqewxgT4cbHVuwEC66B567y92m+DO/tl45xphh4asAMCl7DAWAzmbXWNvd5j6/87C7Z46qq8u/6B434rZX/lx3y4SSS+KXZ2PMCcU3AaCmuZNT43n7h1Dww3r62g/gsatcH/1e44rdfXJSsgZef9pHRj6Pxhhf8UUA6AqGaGjrZlK8qoDeeABevw9ufN71wX/sKpAAXPcYpOVAc7V7nOBghb8xxowAXwSA2uYuAArjUQXUXO3urdPTDr/8rOumKQnwN/8NeQM+QsEYY0ZFQiwLichSEdkqIuUicvcA83NF5FkReV9E3hGRkyLm7RKRDSKyTkTKItLHi8hLIrLde88dnl06VG8X0ILRDgDhsHucYTjoHllYv82lr7DC3xgTf0NeAYhIAHgQ91jHSmCNiKxS1c0Ri90DrFPVa0Rknrf8koj5F6lqfdSm7wZeVtV7vaByN3DXMezLoPZ7g8BGtQqosgye+yfYtxbO/7J7ZOGEWe6e+ZGNu8YYEyexXAEsBspVtcJ76PtTwLKoZRYALwOo6hZguogUDLHdZcBj3ufHgKtjzfSRqmkexQDQ3Qa//SL8eAk07YNrfgQX/W83b+aFVvgbY8aMWNoAioC9EdOVwFlRy6wHrgVeF5HFwDSgGKjBPfT9RRFR4Eeq+pC3ToGqVgOoarWIHOHjoGK3v6mT1KQExqWNYJNHS427+dqLX3O3aDj3DrjgH61h1xgzZsVSIg403FSjpu8F7heRdcAG4D0g6M07V1WrvAL+JRHZoqqvxZpBEbkFuAVg6tSpsa7Wz8nF2XyWaSN3/5/3noBVX3IDuJIyYPmTMHfpyHyXMcYMk1gCQCUQ+aTtYqAqcgFVbQZuBBBXyu70XqhqlfdeKyLP4qqUXgNqRKTQO/svBGoH+nLviuEhgNLS0ujAE5Nli4pYtmiEHjv4zsPuoeYzL4Rz73Qjd4/02bbGGBMHsbQBrAFKRGSGiCQDy4FVkQuISI43D+Bm4DVVbRaRDBHJ8pbJAC4FvIfJsgpY4X1eAfzu2HYlDsr/4Bp6514Jn/4VzLrICn9jzHFjyCsAVQ2KyO3AC0AAeERVN4nIrd78lcB84HERCQGbgZu81QuAZ72ql0TgF6r6vDfvXuBpEbkJ2ANcN3y7NcL+cj+s+wUc2A358+HahyDxOH++gDHGd0T1qGpV4qK0tFTLysqGXnAklb8MP7/W3Y0zfx589J/cs3KNMWaMEpG1qloane6LkcDDprXOdfHMmwsrfm9P2jLGHNcsAMSqswl+fo17/8zTVvgbY457Md0Kwvfa6uFn10LtFvjUz6Hw1HjnyBhjjpldAQylpQYeuQxaquG6R6Hk4njnyBhjhoUFgKG8fh807YW/WQ1TowdAG2PM8cuqgA6ntRbWPgqnLrfC3xhzwrErgME0V8HL/wdC3XDeP8Q7N8YYM+wsAAyk4lX42dXu6V2l3m2cjTHmBGMBYCBrfwpp4+Fv/sc9jN0YY05A1gYQrasVtj4PC5bBxHkwUncQNcaYOLMAEG3b8xDsgJP+Kt45McaYEWUBIJIqrH8Ksgph6jnxzo0xxowoCwC9wiF3X//yl+CMGyHBDo0x5sRmpVyvNT+BNT+Gj/ydu8OnMcac4KwXELiqn3cegqJSuPRb8c6NMcaMCrsCANj5GjRshzNvjndOjDFm1MQUAERkqYhsFZFyEbl7gPm5IvKsiLwvIu+IyEle+hQReUVEPhCRTSJyR8Q63xCRfSKyzntdMXy7dYTKfgJpubDwmrhlwRhjRtuQAUBEAsCDwOXAAuB6EVkQtdg9wDpVPQW4AbjfSw8CX1bV+cDZwG1R635fVRd5r9XHuC9Hp7sNtqyGU5ZDUmpcsmCMMfEQyxXAYqBcVStUtRt4ClgWtcwC4GUAVd0CTBeRAlWtVtV3vfQW4AOgaNhyPxx2vwnhHii5JN45McaYURVLACgC9kZMV3JoIb4euBZARBYD04DiyAVEZDpwGvB2RPLtXrXRIyKSe2RZHyYVr0Ag2fr9G2N8J5YAMNC9EKKfJH8vkCsi64AvAe/hqn/cBkQygd8Ad6pqs5f8Q2AWsAioBr434JeL3CIiZSJSVldXF0N2j9DOV2HKWZCcPvzbNsaYMSyWAFAJTImYLgaqIhdQ1WZVvVFVF+HaAPKBnQAikoQr/J9Q1Wci1qlR1ZCqhoGHcVVNh1DVh1S1VFVL8/PzY9+zWLTVw/4NMPPC4d2uMcYcB2IJAGuAEhGZISLJwHJgVeQCIpLjzQO4GXhNVZtFRICfAB+o6n1R6xRGTF4DbDzanThqO1917zMvGvWvNsaYeBtyIJiqBkXkduAFIAA8oqqbRORWb/5KYD7wuIiEgM3ATd7q5wKfAzZ41UMA93g9fr4jIotw1Um7gC8M107FrOJPkJINkxeN+lcbY0y8xTQS2CuwV0elrYz4/CZQMsB6rzNwGwKq+rkjyulwU4Udf4IZ50NCIK5ZMcaYePDvSOADO6Fpj9X/G2N8y78BoOJP7t0CgDHGp/wdAMYVwYTZ8c6JMcbEhT8DgCrs/DPM+Kg98tEY41v+DADNVdDRCMVnxDsnxhgTN/4MAPVb3XvenPjmwxhj4sifAaBum3vPmxvffBhjTBz5MwDUb4XUbMicGO+cGGNM3Pg0AGx31T/WAGyM8TF/BoC6rVb9Y4zxPf8FgI4D0FYL+dYAbIzxN/8FgPrt7t16ABljfM5/AaDOuoAaYwz4MQA07oCERMidHu+cGGNMXPkvALTWQUa+3QLaGON7/gsA7fWQnhfvXBhjTNz5LwC01UOGBQBjjIkpAIjIUhHZKiLlInL3APNzReRZEXlfRN4RkZOGWldExovISyKy3XvPHZ5dGkK7BQBjjIEYAoCIBIAHgcuBBcD1IrIgarF7gHWqegpwA3B/DOveDbysqiXAy970yGtrsCogY4whtiuAxUC5qlaoajfwFLAsapkFuEIcVd0CTBeRgiHWXQY85n1+DLj6WHYkJj2d0N0CGRNG/KuMMWasiyUAFAF7I6YrvbRI64FrAURkMTANKB5i3QJVrQbw3ge8M5uI3CIiZSJSVldXF0N2D6O93r3bFYAxxsQUAAa6Y5pGTd8L5IrIOuBLwHtAMMZ1D0tVH1LVUlUtzc/PP5JVD9XmBYCMY9yOMcacABJjWKYSmBIxXQxURS6gqs3AjQAiIsBO75V+mHVrRKRQVatFpBCoPao9OBK9VwDWCGyMMTFdAawBSkRkhogkA8uBVZELiEiONw/gZuA1Lygcbt1VwArv8wrgd8e2KzFoa3DvVgVkjDFDXwGoalBEbgdeAALAI6q6SURu9eavBOYDj4tICNgM3HS4db1N3ws8LSI3AXuA64Z31wbQdwVgjcDGGBNLFRCquhpYHZW2MuLzm0BJrOt66Q3AkiPJ7DFrq3f3AUrNGdWvNcaYschfI4F7bwNhTwIzxhifBQC7DYQxxvTxXwBIt/p/Y4wBvwUAuw+QMcb08VcAaGuwQWDGGOPxTwAIdkNXk40BMMYYj38CQE+7e0/JjG8+jDFmjPBPAAiH3HtCTEMfjDHmhOejANDj3u1ZwMYYA/gqAATdu10BGGMM4MsAkBTffBhjzBjhowBgbQDGGBPJPwEgZG0AxhgTyT8BwNoAjDGmH/8FgIC1ARhjDPgqAFgbgDHGRIopAIjIUhHZKiLlInL3APOzReT3IrJeRDaJSO/zgeeKyLqIV7OI3OnN+4aI7IuYd8Ww7lk0GwdgjDH9DHk6LCIB4EHgEtwD4teIyCpV3Ryx2G3AZlW9SkTyga0i8oSqbgUWRWxnH/BsxHrfV9X/HJ5dGYK1ARhjTD+xXAEsBspVtUJVu4GngGVRyyiQJSICZAKNQDBqmSXADlXdfYx5Pjo2DsAYY/qJJQAUAXsjpiu9tEgP4B4MXwVsAO5Q1XDUMsuBJ6PSbheR90XkERHJjT3bRyFkVwDGGBMplgAw0AN0NWr6MmAdMBlX5fOAiIzr24BIMvAJ4FcR6/wQmOUtXw18b8AvF7lFRMpEpKyuri6G7A6i7wrA2gCMMQZiCwCVwJSI6WLcmX6kG4Fn1CkHdgLzIuZfDryrqjW9Capao6oh70rhYVxV0yFU9SFVLVXV0vz8Y3iYi7UBGGNMP7EEgDVAiYjM8M7klwOropbZg6vjR0QKgLlARcT864mq/hGRwojJa4CNR5b1I2TjAIwxpp8hT4dVNSgitwMvAAHgEVXdJCK3evNXAt8CHhWRDbgqo7tUtR5ARNJxPYi+ELXp74jIIlx10q4B5g8vuwIwxph+YioNVXU1sDoqbWXE5yrg0kHWbQcmDJD+uSPK6bGyNgBjjOnHRyOB7QrAGGMi+TAAWBuAMcaAnwJA3+2g7QrAGGPATwGg72Zw1gZgjDHgqwBgbQDGGBPJfwHAxgEYYwzgqwBgbQDGGBPJRwHAawMQawMwxhjwVQAIgiRAgn922RhjDsc/pWE4aGMAjDEmgn8CQKjH6v+NMSaCfwJAOGQBwBhjIvgoAARtEJgxxkTwVwCwMQDGGNPHRwHA2gCMMSaSjwJAyKqAjDEmgo8CQNCuAIwxJkJMAUBElorIVhEpF5G7B5ifLSK/F5H1IrJJRG6MmLdLRDaIyDoRKYtIHy8iL4nIdu89d3h2aRA2DsAYY/oZMgCISAB4ELgcWABcLyILoha7DdisqqcCFwLf8x4g3+siVV2kqqURaXcDL6tqCfCyNz1ybByAMcb0E8sVwGKgXFUrVLUbeApYFrWMAlkiIkAm0AgEh9juMuAx7/NjwNWxZvqoWBuAMcb0E0sAKAL2RkxXemmRHgDmA1XABuAOVQ178xR4UUTWisgtEesUqGo1gPc+caAvF5FbRKRMRMrq6upiyO4grA3AGGP6iSUAyABpGjV9GbAOmAwsAh4QkXHevHNV9XRcFdJtInLBkWRQVR9S1VJVLc3Pzz+SVfsL99g4AGOMiRBLAKgEpkRMF+PO9CPdCDyjTjmwE5gHoKpV3nst8CyuSgmgRkQKAbz32qPdiZjYrSCMMaafWALAGqBERGZ4DbvLgVVRy+wBlgCISAEwF6gQkQwRyfLSM4BLgY3eOquAFd7nFcDvjmVHhmS3gjDGmH6GPCVW1aCI3A68AASAR1R1k4jc6s1fCXwLeFRENuCqjO5S1XoRmQk869qGSQR+oarPe5u+F3haRG7CBZDrhnnf+gsHISltRL/CGGOOJzHViajqamB1VNrKiM9VuLP76PUqgFMH2WYD3lXDqAj12DgAY4yJ4KORwNYGYIwxkXwUAKwNwBhjIvksANgVgDHG9PJRALBxAMYYE8lHAcDaAIwxJpKPAoC1ARhjTCSfBQC7AjDGmF7+CQA2DsAYY/rxTwCwNgBjjOnHRwHA2gCMMSaSzwKAXQEYY0wvfwQAVRsHYIwxUXwSALyHk9kVgDHG9PFHAAh7jye2NgBjjOnjswBgVwDGGNPLHwEg1OPebRyAMcb0iSkAiMhSEdkqIuUicvcA87NF5Pcisl5ENonIjV76FBF5RUQ+8NLviFjnGyKyT0TWea8rhm+3ooRD7t2uAIwxps+QJaKIBIAHgUtwD4hfIyKrVHVzxGK3AZtV9SoRyQe2isgTQBD4sqq+6z0beK2IvBSx7vdV9T+HdY8GYm0AxhhziFiuABYD5apaoardwFPAsqhlFMgS9/DfTKARCKpqtaq+C6CqLcAHQNGw5T5W1gZgjDGHiCUAFAF7I6YrObQQfwCYD1QBG4A7VHv7XjoiMh04DXg7Ivl2EXlfRB4RkdwjzHvswl4bgI0DMMaYPrEEABkgTaOmLwPWAZOBRcADIjKubwMimcBvgDtVtdlL/iEwy1u+GvjegF8ucouIlIlIWV1dXQzZHYC1ARhjzCFiCQCVwJSI6WLcmX6kG4Fn1CkHdgLzAEQkCVf4P6Gqz/SuoKo1qhryrhQexlU1HUJVH1LVUlUtzc/Pj3W/+rM2AGOMOUQsAWANUCIiM0QkGVgOrIpaZg+wBEBECoC5QIXXJvAT4ANVvS9yBREpjJi8Bth4dLsQg75uoHYFYIwxvYYsEVU1KCK3Ay8AAeARVd0kIrd681cC3wIeFZENuCqju1S1XkTOAz4HbBCRdd4m71HV1cB3RGQRrjppF/CFYd2zSH1XANYGYIwxvWI6JfYK7NVRaSsjPlcBlw6w3usM3IaAqn7uiHJ6LKwNwBhjDuGPkcDWBmCMMYfwSQCwNgBjjInmkwDgXQHYOABjjOnjrwBgVwDGGNPHJwGgtxHY2gCMMaaXPwKAjQMwxphD+CMA2DgAY4w5hM8CgF0BGGNML58EAGsDMMaYaD4JANYGYIwx0XwSAGwcgDHGRPNXALArAGOM6eOTAGA3gzPGmGj+CAB94wCsEdgYY3r5IwDYOABjjDmEzwKAVQEZY0yvmAKAiCwVka0iUi4idw8wP1tEfi8i60Vkk4jcONS6IjJeRF4Ske3ee+7w7NIArA3AGGMOMWQAEJEA8CBwObAAuF5EFkQtdhuwWVVPBS4EviciyUOsezfwsqqWAC970yMj3AMIJPjjgscYY2IRS4m4GChX1QpV7QaeApZFLaNAlvcQ+EygEQgOse4y4DHv82PA1ceyI4cVDtoYAGOMiRJLACgC9kZMV3ppkR4A5gNVwAbgDlUND7FugapWA3jvE48497EKB636xxhjosQSAAZ6qLtGTV8GrAMmA4uAB0RkXIzrHv7LRW4RkTIRKaurqzuSVT8UDlkAMMaYKLEEgEpgSsR0Me5MP9KNwDPqlAM7gXlDrFsjIoUA3nvtQF+uqg+paqmqlubn58eQ3QGEemwMgDHGRIklAKwBSkRkhogkA8uBVVHL7AGWAIhIATAXqBhi3VXACu/zCuB3x7IjhzXpZJh35Yht3hhjjkdD1ouoalBEbgdeAALAI6q6SURu9eavBL4FPCoiG3DVPnepaj3AQOt6m74XeFpEbsIFkOuGd9cinLHCvYwxxvQR1SOqko+r0tJSLSsri3c2jDHmuCIia1W1NDrdOsYbY4xPWQAwxhifsgBgjDE+ZQHAGGN8ygKAMcb4lAUAY4zxKQsAxhjjU8fVOAARqQN2H+XqeUD9MGZnuIzVfMHYzZvl68iM1XzB2M3biZavaap6yL10jqsAcCxEpGyggRDxNlbzBWM3b5avIzNW8wVjN29+yZdVARljjE9ZADDGGJ/yUwB4KN4ZGMRYzReM3bxZvo7MWM0XjN28+SJfvmkDMMYY05+frgCMMcZE8EUAEJGlIrJVRMpF5O445mOKiLwiIh+IyCYRucNL/4aI7BORdd7rijjkbZeIbPC+v8xLGy8iL4nIdu89d5TzNDfimKwTkWYRuTNex0tEHhGRWhHZGJE26DESkX/2fnNbReSyUc7Xd0Vki4i8LyLPikiOlz5dRDoijt3KUc7XoH+7OB+vX0bkaZeIrPPSR/N4DVY+jNxvTFVP6BfuQTQ7gJlAMrAeWBCnvBQCp3ufs4BtwALgG8BX4nycdgF5UWnfAe72Pt8N/Eec/477gWnxOl7ABcDpwMahjpH3d10PpAAzvN9gYBTzdSmQ6H3+j4h8TY9cLg7Ha8C/XbyPV9T87wH/EofjNVj5MGK/MT9cASwGylW1QlW7gaeAZfHIiKpWq+q73ucW4AOgKB55idEy4DHv82PA1fHLCkuAHap6tAMBj5mqvgY0RiUPdoyWAU+papeq7gTKcb/FUcmXqr6oqkFv8i3c87hH1SDHazBxPV69RESATwJPjsR3H85hyocR+435IQAUAXsjpisZA4WuiEwHTgPe9pJu9y7XHxntqhaPAi+KyFoRucVLK1DVanA/TmBiHPLVazn9/ynjfbx6DXaMxtLv7vPAcxHTM0TkPRF5VUTOj0N+BvrbjZXjdT5Qo6rbI9JG/XhFlQ8j9hvzQwCQAdLi2vVJRDKB3wB3qmoz8ENgFrAIqMZdgo62c1X1dOBy4DYRuSAOeRiQiCQDnwB+5SWNheM1lDHxuxORrwJB4AkvqRqYqqqnAf8A/EJExo1ilgb7242J4wVcT/8TjVE/XgOUD4MuOkDaER0zPwSASmBKxHQxUBWnvCAiSbg/7hOq+gyAqtaoakhVw8DDjNCl7+GoapX3Xgs86+WhRkQKvXwXArWjnS/P5cC7qlrj5THuxyvCYMco7r87EVkBfBz4jHqVxl51QYP3eS2u3njOaOXpMH+7sXC8EoFrgV/2po328RqofGAEf2N+CABrgBIRmeGdSS4HVsUjI1794k+AD1T1voj0wojFrgE2Rq87wvnKEJGs3s+4BsSNuOO0wltsBfC70cxXhH5nZfE+XlEGO0argOUikiIiM4AS4J3RypSILAXuAj6hqu0R6fkiEvA+z/TyVTGK+RrsbxfX4+W5GNiiqpW9CaN5vAYrHxjJ39hotG7H+wVcgWtR3wF8NY75OA93ifY+sM57XQH8DNjgpa8CCkc5XzNxvQnWA5t6jxEwAXgZ2O69j4/DMUsHGoDsiLS4HC9cEKoGenBnXzcd7hgBX/V+c1uBy0c5X+W4+uHe39lKb9m/8v7G64F3gatGOV+D/u3ieby89EeBW6OWHc3jNVj5MGK/MRsJbIwxPuWHKiBjjDEDsABgjDE+ZQHAGGN8ygKAMcb4lAUAY4zxKQsAxhjjUxYAjDHGpywAGGOMT/1/inQbMVutxnoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d490cc1f",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b4d2a6f035b4d84d1cd6d1542a6a4821",
     "grade": true,
     "grade_id": "cell-fb13bc28bec0a325",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0247 - accuracy: 0.9927\n",
      "Test loss: 0.02472463808953762\n",
      "Test accuracy: 0.9926999807357788\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7b7ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/3Layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "93d3023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### testing for second benchmark does not improve performance\n",
    "\n",
    "leNet = keras.Sequential()\n",
    "\n",
    "leNet.add(keras.layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', padding='same',\n",
    "                              input_shape=(28,28,1)))\n",
    "leNet.add(keras.layers.AveragePooling2D())\n",
    "\n",
    "leNet.add(keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "leNet.add(keras.layers.AveragePooling2D())\n",
    "\n",
    "leNet.add(keras.layers.Flatten())\n",
    "\n",
    "leNet.add(keras.layers.Dense(units=512, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "leNet.add(keras.layers.Dense(units=256, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.4))\n",
    "leNet.add(keras.layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "leNet.add(keras.layers.Dense(units=10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27605688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.0996 - val_accuracy: 0.9827 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0077 - accuracy: 0.9975 - val_loss: 0.0865 - val_accuracy: 0.9865 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0729 - val_accuracy: 0.9856 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0083 - accuracy: 0.9971 - val_loss: 0.0563 - val_accuracy: 0.9898 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0099 - accuracy: 0.9965 - val_loss: 0.0658 - val_accuracy: 0.9872 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0068 - accuracy: 0.9976 - val_loss: 0.0784 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0720 - val_accuracy: 0.9854 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0774 - val_accuracy: 0.9847 - lr: 9.0000e-05\n",
      "Epoch 9/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 0.0609 - val_accuracy: 0.9877 - lr: 9.0000e-05\n",
      "Epoch 10/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0049 - accuracy: 0.9983 - val_loss: 0.0561 - val_accuracy: 0.9891 - lr: 9.0000e-05\n",
      "Epoch 11/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0054 - accuracy: 0.9983 - val_loss: 0.0681 - val_accuracy: 0.9866 - lr: 9.0000e-05\n",
      "Epoch 12/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0045 - accuracy: 0.9985 - val_loss: 0.0593 - val_accuracy: 0.9881 - lr: 9.0000e-05\n",
      "Epoch 13/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0036 - accuracy: 0.9988 - val_loss: 0.0647 - val_accuracy: 0.9884 - lr: 9.0000e-05\n",
      "Epoch 14/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0033 - accuracy: 0.9990 - val_loss: 0.0671 - val_accuracy: 0.9872 - lr: 8.1000e-05\n",
      "Epoch 15/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0031 - accuracy: 0.9991 - val_loss: 0.0593 - val_accuracy: 0.9888 - lr: 8.1000e-05\n",
      "Epoch 16/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 0.0038 - accuracy: 0.9988 - val_loss: 0.0615 - val_accuracy: 0.9890 - lr: 8.1000e-05\n",
      "Epoch 17/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0606 - val_accuracy: 0.9896 - lr: 7.2900e-05\n",
      "Epoch 18/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0036 - accuracy: 0.9989 - val_loss: 0.0663 - val_accuracy: 0.9886 - lr: 7.2900e-05\n",
      "Epoch 19/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0662 - val_accuracy: 0.9891 - lr: 7.2900e-05\n",
      "Epoch 20/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 5.9148e-04 - accuracy: 1.0000 - val_loss: 0.0606 - val_accuracy: 0.9895 - lr: 6.5610e-05\n",
      "Epoch 21/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0608 - val_accuracy: 0.9894 - lr: 6.5610e-05\n",
      "Epoch 22/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0629 - val_accuracy: 0.9892 - lr: 6.5610e-05\n",
      "Epoch 23/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0014 - accuracy: 0.9995 - val_loss: 0.0606 - val_accuracy: 0.9894 - lr: 5.9049e-05\n",
      "Epoch 24/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3.8691e-04 - accuracy: 1.0000 - val_loss: 0.0650 - val_accuracy: 0.9887 - lr: 5.9049e-05\n",
      "Epoch 25/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.0649 - val_accuracy: 0.9891 - lr: 5.9049e-05\n",
      "Epoch 26/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 5.6931e-04 - accuracy: 0.9999 - val_loss: 0.0659 - val_accuracy: 0.9892 - lr: 5.3144e-05\n",
      "Epoch 27/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.0777 - val_accuracy: 0.9874 - lr: 5.3144e-05\n",
      "Epoch 28/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0620 - val_accuracy: 0.9902 - lr: 5.3144e-05\n",
      "Epoch 29/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3.8545e-04 - accuracy: 1.0000 - val_loss: 0.0706 - val_accuracy: 0.9886 - lr: 4.7830e-05\n",
      "Epoch 30/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 8.9805e-04 - accuracy: 0.9998 - val_loss: 0.0626 - val_accuracy: 0.9899 - lr: 4.7830e-05\n",
      "Epoch 31/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 5.3092e-04 - accuracy: 0.9999 - val_loss: 0.0634 - val_accuracy: 0.9900 - lr: 4.7830e-05\n",
      "Epoch 32/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.1334e-04 - accuracy: 1.0000 - val_loss: 0.0639 - val_accuracy: 0.9899 - lr: 4.3047e-05\n",
      "Epoch 33/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0851 - val_accuracy: 0.9887 - lr: 4.3047e-05\n",
      "Epoch 34/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 5.2563e-04 - accuracy: 0.9999 - val_loss: 0.0691 - val_accuracy: 0.9894 - lr: 4.3047e-05\n",
      "Epoch 35/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 9.2563e-05 - accuracy: 1.0000 - val_loss: 0.0691 - val_accuracy: 0.9900 - lr: 3.8742e-05\n",
      "Epoch 36/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.0983e-04 - accuracy: 1.0000 - val_loss: 0.0682 - val_accuracy: 0.9905 - lr: 3.8742e-05\n",
      "Epoch 37/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 8.1635e-04 - accuracy: 0.9998 - val_loss: 0.0726 - val_accuracy: 0.9886 - lr: 3.8742e-05\n",
      "Epoch 38/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 5.1603e-04 - accuracy: 0.9999 - val_loss: 0.0679 - val_accuracy: 0.9899 - lr: 3.4868e-05\n",
      "Epoch 39/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 5.6206e-05 - accuracy: 1.0000 - val_loss: 0.0700 - val_accuracy: 0.9898 - lr: 3.4868e-05\n",
      "Epoch 40/100\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 1.7514e-04 - accuracy: 0.9999 - val_loss: 0.0713 - val_accuracy: 0.9898 - lr: 3.4868e-05\n",
      "Epoch 41/100\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 1.2529e-04 - accuracy: 1.0000 - val_loss: 0.0731 - val_accuracy: 0.9902 - lr: 3.1381e-05\n",
      "Epoch 42/100\n",
      "1500/1500 [==============================] - 14s 10ms/step - loss: 1.7935e-04 - accuracy: 1.0000 - val_loss: 0.0757 - val_accuracy: 0.9896 - lr: 3.1381e-05\n",
      "Epoch 43/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.8271e-04 - accuracy: 1.0000 - val_loss: 0.0707 - val_accuracy: 0.9902 - lr: 3.1381e-05\n",
      "Epoch 44/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3.8047e-05 - accuracy: 1.0000 - val_loss: 0.0722 - val_accuracy: 0.9902 - lr: 2.8243e-05\n",
      "Epoch 45/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 6.4226e-05 - accuracy: 1.0000 - val_loss: 0.0739 - val_accuracy: 0.9897 - lr: 2.8243e-05\n",
      "Epoch 46/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.6003e-04 - accuracy: 1.0000 - val_loss: 0.0735 - val_accuracy: 0.9898 - lr: 2.8243e-05\n",
      "Epoch 47/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3.3020e-05 - accuracy: 1.0000 - val_loss: 0.0734 - val_accuracy: 0.9904 - lr: 2.5419e-05\n",
      "Epoch 48/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3.6162e-05 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9901 - lr: 2.5419e-05\n",
      "Epoch 49/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.7197e-04 - accuracy: 0.9999 - val_loss: 0.0782 - val_accuracy: 0.9898 - lr: 2.5419e-05\n",
      "Epoch 50/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 5.0629e-05 - accuracy: 1.0000 - val_loss: 0.0812 - val_accuracy: 0.9894 - lr: 2.2877e-05\n",
      "Epoch 51/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3.8212e-04 - accuracy: 0.9999 - val_loss: 0.0768 - val_accuracy: 0.9898 - lr: 2.2877e-05\n",
      "Epoch 52/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.6463e-05 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9900 - lr: 2.2877e-05\n",
      "Epoch 53/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.8069e-05 - accuracy: 1.0000 - val_loss: 0.0764 - val_accuracy: 0.9900 - lr: 2.0589e-05\n",
      "Epoch 54/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.7761e-05 - accuracy: 1.0000 - val_loss: 0.0771 - val_accuracy: 0.9899 - lr: 2.0589e-05\n",
      "Epoch 55/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.5928e-05 - accuracy: 1.0000 - val_loss: 0.0789 - val_accuracy: 0.9898 - lr: 2.0589e-05\n",
      "Epoch 56/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.2266e-05 - accuracy: 1.0000 - val_loss: 0.0794 - val_accuracy: 0.9895 - lr: 1.8530e-05\n",
      "Epoch 57/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 6.8325e-05 - accuracy: 1.0000 - val_loss: 0.0838 - val_accuracy: 0.9898 - lr: 1.8530e-05\n",
      "Epoch 58/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 9.7030e-06 - accuracy: 1.0000 - val_loss: 0.0817 - val_accuracy: 0.9898 - lr: 1.8530e-05\n",
      "Epoch 59/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 7.9326e-06 - accuracy: 1.0000 - val_loss: 0.0828 - val_accuracy: 0.9895 - lr: 1.6677e-05\n",
      "Epoch 60/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 7.2959e-06 - accuracy: 1.0000 - val_loss: 0.0829 - val_accuracy: 0.9898 - lr: 1.6677e-05\n",
      "Epoch 61/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 2.7422e-05 - accuracy: 1.0000 - val_loss: 0.0862 - val_accuracy: 0.9893 - lr: 1.6677e-05\n",
      "Epoch 62/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 6.5814e-06 - accuracy: 1.0000 - val_loss: 0.0880 - val_accuracy: 0.9896 - lr: 1.5009e-05\n",
      "Epoch 63/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 6.0017e-06 - accuracy: 1.0000 - val_loss: 0.0870 - val_accuracy: 0.9896 - lr: 1.5009e-05\n",
      "Epoch 64/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 6.4971e-06 - accuracy: 1.0000 - val_loss: 0.0873 - val_accuracy: 0.9892 - lr: 1.5009e-05\n",
      "Epoch 65/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 1.3546e-05 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9897 - lr: 1.3509e-05\n",
      "Epoch 66/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 6.7742e-06 - accuracy: 1.0000 - val_loss: 0.0915 - val_accuracy: 0.9898 - lr: 1.3509e-05\n",
      "Epoch 67/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3.4019e-06 - accuracy: 1.0000 - val_loss: 0.0903 - val_accuracy: 0.9898 - lr: 1.3509e-05\n",
      "Epoch 68/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3.1968e-06 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9900 - lr: 1.2158e-05\n",
      "Epoch 69/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 4.8763e-06 - accuracy: 1.0000 - val_loss: 0.0922 - val_accuracy: 0.9898 - lr: 1.2158e-05\n",
      "Epoch 70/100\n",
      "1500/1500 [==============================] - 14s 9ms/step - loss: 3.4153e-06 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9897 - lr: 1.2158e-05\n",
      "Epoch 71/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.1556e-06 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9898 - lr: 1.0942e-05\n",
      "Epoch 72/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.1870e-06 - accuracy: 1.0000 - val_loss: 0.0953 - val_accuracy: 0.9896 - lr: 1.0942e-05\n",
      "Epoch 73/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.0466e-06 - accuracy: 1.0000 - val_loss: 0.0971 - val_accuracy: 0.9896 - lr: 1.0942e-05\n",
      "Epoch 74/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.8926e-06 - accuracy: 1.0000 - val_loss: 0.0976 - val_accuracy: 0.9899 - lr: 9.8477e-06\n",
      "Epoch 75/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.6070e-06 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9895 - lr: 9.8477e-06\n",
      "Epoch 76/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.4933e-06 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9896 - lr: 9.8477e-06\n",
      "Epoch 77/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.2903e-06 - accuracy: 1.0000 - val_loss: 0.0998 - val_accuracy: 0.9898 - lr: 8.8629e-06\n",
      "Epoch 78/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 9.3840e-07 - accuracy: 1.0000 - val_loss: 0.1008 - val_accuracy: 0.9898 - lr: 8.8629e-06\n",
      "Epoch 79/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.1493e-06 - accuracy: 1.0000 - val_loss: 0.1020 - val_accuracy: 0.9898 - lr: 8.8629e-06\n",
      "Epoch 80/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 8.9245e-07 - accuracy: 1.0000 - val_loss: 0.1053 - val_accuracy: 0.9896 - lr: 7.9766e-06\n",
      "Epoch 81/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 7.2059e-07 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9897 - lr: 7.9766e-06\n",
      "Epoch 82/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 5.7943e-07 - accuracy: 1.0000 - val_loss: 0.1048 - val_accuracy: 0.9898 - lr: 7.9766e-06\n",
      "Epoch 83/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 5.8894e-07 - accuracy: 1.0000 - val_loss: 0.1070 - val_accuracy: 0.9897 - lr: 7.1790e-06\n",
      "Epoch 84/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 4.7132e-07 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9898 - lr: 7.1790e-06\n",
      "Epoch 85/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 6.0980e-07 - accuracy: 1.0000 - val_loss: 0.1093 - val_accuracy: 0.9897 - lr: 7.1790e-06\n",
      "Epoch 86/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 4.7415e-07 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9898 - lr: 6.4611e-06\n",
      "Epoch 87/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3.4741e-07 - accuracy: 1.0000 - val_loss: 0.1099 - val_accuracy: 0.9895 - lr: 6.4611e-06\n",
      "Epoch 88/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3.4810e-07 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9898 - lr: 6.4611e-06\n",
      "Epoch 89/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3.3956e-07 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9895 - lr: 5.8150e-06\n",
      "Epoch 90/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 3.1100e-07 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9895 - lr: 5.8150e-06\n",
      "Epoch 91/100\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 2.5108e-07 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9896 - lr: 5.8150e-06\n",
      "Epoch 92/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.7459e-07 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9898 - lr: 5.2335e-06\n",
      "Epoch 93/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.3574e-07 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9897 - lr: 5.2335e-06\n",
      "Epoch 94/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 2.2389e-07 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9898 - lr: 5.2335e-06\n",
      "Epoch 95/100\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 2.0088e-07 - accuracy: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9895 - lr: 4.7101e-06\n",
      "Epoch 96/100\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 1.8943e-07 - accuracy: 1.0000 - val_loss: 0.1166 - val_accuracy: 0.9893 - lr: 4.7101e-06\n",
      "Epoch 97/100\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 1.7532e-07 - accuracy: 1.0000 - val_loss: 0.1170 - val_accuracy: 0.9898 - lr: 4.7101e-06\n",
      "Epoch 98/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.6869e-07 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9897 - lr: 4.2391e-06\n",
      "Epoch 99/100\n",
      "1500/1500 [==============================] - 13s 9ms/step - loss: 1.4956e-07 - accuracy: 1.0000 - val_loss: 0.1175 - val_accuracy: 0.9896 - lr: 4.2391e-06\n",
      "Epoch 100/100\n",
      "1500/1500 [==============================] - 13s 8ms/step - loss: 1.4969e-07 - accuracy: 1.0000 - val_loss: 0.1184 - val_accuracy: 0.9896 - lr: 4.2391e-06\n"
     ]
    }
   ],
   "source": [
    "leNet.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "            optimizer=keras.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "le_history = leNet.fit(x_train_augmented, y_train_augmented, epochs=100, batch_size=32, validation_data=(x_val, y_val), callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82479af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0639 - accuracy: 0.9890\n",
      "Test loss: 0.08708471059799194\n",
      "Test accuracy: 0.9797999858856201\n"
     ]
    }
   ],
   "source": [
    "Le_score = leNet.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
